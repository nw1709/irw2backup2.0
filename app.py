import streamlit as st
from anthropic import Anthropic
from PIL import Image
import google.generativeai as genai
import logging
import hashlib

# --- Logger Setup ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- API Key Validation ---
def validate_keys():
    required_keys = {
        'gemini_key': ('AIza', "Gemini"),
        'claude_key': ('sk-ant', "Claude")
    }
    missing = []
    invalid = []
    
    for key, (prefix, name) in required_keys.items():
        if key not in st.secrets:
            missing.append(name)
        elif not st.secrets[key].startswith(prefix):
            invalid.append(name)
    
    if missing or invalid:
        st.error(f"API Key Problem: Missing {', '.join(missing)} | Invalid {', '.join(invalid)}")
        st.stop()

validate_keys()

# --- UI-Einstellungen ---
st.set_page_config(layout="centered", page_title="Koifox-Bot", page_icon="ü¶ä")
st.title("ü¶ä Koifox-Bot")
st.markdown("*Single-Model System mit verbessertem Prompting*")

# --- Gemini Flash Konfiguration ---
genai.configure(api_key=st.secrets["gemini_key"])
vision_model = genai.GenerativeModel("gemini-1.5-flash")

# --- OCR mit Caching ---
@st.cache_data(ttl=3600)
def extract_text_with_gemini(_image, file_hash):
    """Extrahiert Text aus Bild - gecached basierend auf file_hash"""
    try:
        logger.info(f"Starting OCR for file hash: {file_hash}")
        response = vision_model.generate_content(
            [
                "Extract ALL text from this exam image EXACTLY as written. Include all question numbers, text, and answer options (A, B, C, D, E). Do NOT interpret or solve.",
                _image
            ],
            generation_config={
                "temperature": 0,
                "max_output_tokens": 4000
            }
        )
        logger.info("OCR completed successfully")
        return response.text.strip()
    except Exception as e:
        logger.error(f"Gemini OCR Error: {str(e)}")
        raise e

# --- Claude Solver mit verbesserten Prompts ---
def solve_with_claude(ocr_text, iteration=1):
    """Claude l√∂st die Aufgabe mit expliziten Regeln"""
    
    prompt = f"""Du bist ein Experte f√ºr "Internes Rechnungswesen (31031)" an der Fernuni Hagen.

KRITISCHE REGELN (SEHR WICHTIG!):
- Eine Funktion f(r‚ÇÅ,r‚ÇÇ) = (r‚ÇÅ^Œ± + r‚ÇÇ^Œ≤)^Œ≥ ist NUR homogen wenn Œ± = Œ≤
- Wenn nur Œ± + Œ≤ gegeben ist (ohne Œ± = Œ≤), ist die Funktion NICHT homogen
- Homogenit√§tsgrad k bedeutet: f(Œªr) = Œª^k¬∑f(r) f√ºr ALLE Œª
- Pr√ºfe IMMER ob die Bedingungen f√ºr mathematische Eigenschaften erf√ºllt sind
- Mache KEINE unbegr√ºndeten Annahmen

ANALYSIERE DIESEN TEXT (Iteration {iteration}):
{ocr_text}

DENKE SCHRITT F√úR SCHRITT:
1. Was ist gegeben?
2. Was ist gefragt?
3. Welche Bedingungen m√ºssen f√ºr die Eigenschaft erf√ºllt sein?
4. Sind diese Bedingungen erf√ºllt?
5. Was ist die korrekte Antwort?

FORMAT (WICHTIG):
Aufgabe [Nr]: [Antwort - NUR Buchstabe(n) oder Zahl]
Begr√ºndung: [Kurze Erkl√§rung auf Deutsch mit Fachbegriffen]

Beispiel:
Aufgabe 1: CD
Begr√ºndung: Die Produktionsfunktion ist nicht homogen, da Œ± ‚â† Œ≤ im allgemeinen Fall."""

    client = Anthropic(api_key=st.secrets["claude_key"])
    response = client.messages.create(
        model="claude-4-opus-20250514",
        max_tokens=2000,
        temperature=0.1,  # Leicht erh√∂ht f√ºr besseres Reasoning
        system="Du bist ein pr√§ziser Mathematik-Experte. Bei Homogenit√§t: Eine Funktion ist NUR homogen wenn ALLE Bedingungen erf√ºllt sind. Pr√ºfe kritisch!",
        messages=[{"role": "user", "content": prompt}]
    )
    
    return response.content[0].text

# --- Selbst-Verifikation ---
def verify_solution(ocr_text, first_solution):
    """Claude verifiziert seine eigene L√∂sung"""
    
    verify_prompt = f"""Du bist ein ZWEITER, unabh√§ngiger Experte. Pr√ºfe diese L√∂sung SEHR KRITISCH:

AUFGABENTEXT:
{ocr_text}

ZU PR√úFENDE L√ñSUNG:
{first_solution}

KRITISCHE PR√úFPUNKTE:
- Bei Homogenit√§t: f(r‚ÇÅ,r‚ÇÇ) = (r‚ÇÅ^Œ± + r‚ÇÇ^Œ≤)^Œ≥ ist NUR homogen wenn Œ± = Œ≤
- Hat der erste Experte unbegr√ºndete Annahmen gemacht?
- Stimmen die mathematischen Schlussfolgerungen?
- Ist die Antwort wirklich korrekt?

Wenn die L√∂sung FALSCH ist, gib die KORREKTE L√∂sung.
Wenn sie RICHTIG ist, best√§tige sie.

FORMAT:
PR√úFUNG: [KORREKT/FALSCH]
Aufgabe [Nr]: [Finale Antwort]
Begr√ºndung: [Erkl√§rung]"""

    client = Anthropic(api_key=st.secrets["claude_key"])
    response = client.messages.create(
        model="claude-4-opus-20250514",
        max_tokens=2000,
        temperature=0.2,  # Etwas h√∂her f√ºr kritisches Denken
        messages=[{"role": "user", "content": verify_prompt}]
    )
    
    return response.content[0].text

# --- UI ---
# Debug-Modus
debug_mode = st.checkbox("üîç Debug-Modus", value=False, help="Zeigt Zwischenschritte")

# Zwei-Durchg√§nge Option
use_verification = st.checkbox("‚úÖ Mit Selbst-Verifikation", value=True, help="Claude pr√ºft seine eigene L√∂sung")

# Datei-Upload
uploaded_file = st.file_uploader(
    "**Klausuraufgabe hochladen...**",
    type=["png", "jpg", "jpeg"],
    key="file_uploader"
)

if uploaded_file is not None:
    try:
        # Eindeutiger Hash f√ºr die Datei
        file_bytes = uploaded_file.getvalue()
        file_hash = hashlib.md5(file_bytes).hexdigest()
        
        # Bild laden und anzeigen
        image = Image.open(uploaded_file)
        st.image(image, caption="Hochgeladene Klausuraufgabe", use_container_width=True)
        
        # OCR (gecached)
        with st.spinner("üìñ Lese Text mit Gemini Flash..."):
            ocr_text = extract_text_with_gemini(image, file_hash)
            
        # Debug: OCR-Ergebnis anzeigen
        if debug_mode:
            with st.expander("üîç OCR-Ergebnis", expanded=False):
                st.code(ocr_text)
        
        # Button zum L√∂sen
        if st.button("üßÆ Aufgaben l√∂sen", type="primary"):
            st.markdown("---")
            
            # Erste L√∂sung
            with st.spinner("üßÆ Claude l√∂st die Aufgabe..."):
                first_solution = solve_with_claude(ocr_text, iteration=1)
            
            if debug_mode:
                with st.expander("üîç Erste L√∂sung"):
                    st.code(first_solution)
            
            # Verifikation wenn aktiviert
            if use_verification:
                with st.spinner("‚úÖ Claude verifiziert die L√∂sung..."):
                    final_solution = verify_solution(ocr_text, first_solution)
                
                if debug_mode:
                    with st.expander("üîç Verifizierte L√∂sung"):
                        st.code(final_solution)
            else:
                final_solution = first_solution
            
            # Ergebnisse anzeigen
            st.markdown("### üìä L√∂sung:")
            
            # Formatierte Ausgabe
            lines = final_solution.split('\n')
            for line in lines:
                if line.strip():
                    if line.startswith('Aufgabe'):
                        parts = line.split(':', 1)
                        if len(parts) == 2:
                            st.markdown(f"### {parts[0]}: **{parts[1].strip()}**")
                        else:
                            st.markdown(f"### {line}")
                    elif line.startswith('Begr√ºndung:'):
                        st.markdown(f"*{line}*")
                    elif line.startswith('PR√úFUNG:'):
                        if 'KORREKT' in line:
                            st.success("‚úÖ L√∂sung wurde verifiziert")
                        else:
                            st.warning("‚ö†Ô∏è L√∂sung wurde korrigiert")
                    else:
                        if line.strip() and not line.startswith('---'):
                            st.markdown(line)
                    
    except Exception as e:
        logger.error(f"General error: {str(e)}")
        st.error(f"‚ùå Fehler: {str(e)}")

# --- Footer ---
st.markdown("---")
st.caption("Made by Fox | Claude Only mit verbessertem Prompting")
